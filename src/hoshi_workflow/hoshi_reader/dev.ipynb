{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d44199a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the aggregated hoshi_workflow namespace for imports\n",
    "import hoshi_workflow.hoshi_reader as hr\n",
    "import importlib\n",
    "\n",
    "# If you edit the underlying module and want to reload in a running\n",
    "# notebook kernel, reload the module object referenced by `hr`:\n",
    "importlib.reload(hr)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2788c94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tanby/repos/HOSHI_WorkFlow/examples/example_model/fake_model/summary\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/tanby/repos/HOSHI_WorkFlow/examples/example_model/fake_model\"\n",
    "hm = hr.HoshiModel(path)\n",
    "print(hm.summary_dir)  # True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dacab7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tanby/repos/HOSHI_WorkFlow/examples/example_model/fake_model/summary/summary.txt\n",
      "9\n",
      "[{'index': 1, 'header': '# 1:stg 2:jcma 3:nmlo  4:ndv         5:time        6:dtime         7:Mtot         8:Etot         9:Jtot     10:dMdt     11:frot   12:dens_c   13:temp_c    14:Rsurf    15:Lsurf     16:Teff     17:vrot    18:[N/H]     19:Gedd  20:gam_ave 21:mach_max     22:Brad    23:fconf    24:fbrak    25:eta_B26:omgs[d-1]27:omgc[d-1]     28:Lnuc      29:Lnu     30:Lrad', 'start_line': 0, 'end_line': 38, 'var_names': ['stg', 'jcma', 'nmlo', 'ndv', 'time', 'dtime', 'Mtot', 'Etot', 'Jtot', 'dMdt', 'frot', 'dens_c', 'temp_c', 'Rsurf', 'Lsurf', 'Teff', 'vrot', '[N/H]', 'Gedd', 'gam_ave', 'mach_max', 'Brad', 'fconf', 'fbrak', 'eta_B', 'omgs[d-1]', 'omgc[d-1]', 'Lnuc', 'Lnu', 'Lrad']}, {'index': 2, 'header': '# 1:stg 2:jcma 3:nmlo  4:ndv         5:time        6:dtime         7:Mtot         8:Etot         9:Jtot     10:dMdt     11:frot   12:dens_c   13:temp_c    14:Rsurf    15:Lsurf     16:Teff     17:vrot    18:[N/H]     19:Gedd  20:gam_ave 21:mach_max     22:Brad    23:fconf    24:fbrak    25:eta_B26:omgs[d-1]27:omgc[d-1]     28:Lnuc      29:Lnu     30:Lrad', 'start_line': 39, 'end_line': 79, 'var_names': ['stg', 'jcma', 'nmlo', 'ndv', 'time', 'dtime', 'Mtot', 'Etot', 'Jtot', 'dMdt', 'frot', 'dens_c', 'temp_c', 'Rsurf', 'Lsurf', 'Teff', 'vrot', '[N/H]', 'Gedd', 'gam_ave', 'mach_max', 'Brad', 'fconf', 'fbrak', 'eta_B', 'omgs[d-1]', 'omgc[d-1]', 'Lnuc', 'Lnu', 'Lrad']}, {'index': 3, 'header': '# 1:stg 2:jcma 3:nmlo  4:ndv         5:time        6:dtime         7:Mtot         8:Etot         9:Jtot     10:dMdt     11:frot   12:dens_c   13:temp_c    14:Rsurf    15:Lsurf     16:Teff     17:vrot    18:[N/H]     19:Gedd  20:gam_ave 21:mach_max     22:Brad    23:fconf    24:fbrak    25:eta_B26:omgs[d-1]27:omgc[d-1]     28:Lnuc      29:Lnu     30:Lrad', 'start_line': 80, 'end_line': 117, 'var_names': ['stg', 'jcma', 'nmlo', 'ndv', 'time', 'dtime', 'Mtot', 'Etot', 'Jtot', 'dMdt', 'frot', 'dens_c', 'temp_c', 'Rsurf', 'Lsurf', 'Teff', 'vrot', '[N/H]', 'Gedd', 'gam_ave', 'mach_max', 'Brad', 'fconf', 'fbrak', 'eta_B', 'omgs[d-1]', 'omgc[d-1]', 'Lnuc', 'Lnu', 'Lrad']}, {'index': 4, 'header': '# 1:stg 2:jcma 3:nmlo  4:ndv         5:time        6:dtime         7:Mtot         8:Etot         9:Jtot     10:dMdt     11:frot   12:dens_c   13:temp_c    14:Rsurf    15:Lsurf     16:Teff     17:vrot    18:[N/H]     19:Gedd  20:gam_ave 21:mach_max     22:Brad    23:fconf    24:fbrak    25:eta_B26:omgs[d-1]27:omgc[d-1]     28:Lnuc      29:Lnu     30:Lrad', 'start_line': 118, 'end_line': 154, 'var_names': ['stg', 'jcma', 'nmlo', 'ndv', 'time', 'dtime', 'Mtot', 'Etot', 'Jtot', 'dMdt', 'frot', 'dens_c', 'temp_c', 'Rsurf', 'Lsurf', 'Teff', 'vrot', '[N/H]', 'Gedd', 'gam_ave', 'mach_max', 'Brad', 'fconf', 'fbrak', 'eta_B', 'omgs[d-1]', 'omgc[d-1]', 'Lnuc', 'Lnu', 'Lrad']}, {'index': 5, 'header': '# 1:stg 2:jcma 3:nmlo  4:ndv         5:time        6:dtime         7:Mtot         8:Etot         9:Jtot     10:dMdt     11:frot   12:dens_c   13:temp_c    14:Rsurf    15:Lsurf     16:Teff     17:vrot    18:[N/H]     19:Gedd  20:gam_ave 21:mach_max     22:Brad    23:fconf    24:fbrak    25:eta_B26:omgs[d-1]27:omgc[d-1]     28:Lnuc      29:Lnu     30:Lrad', 'start_line': 155, 'end_line': 190, 'var_names': ['stg', 'jcma', 'nmlo', 'ndv', 'time', 'dtime', 'Mtot', 'Etot', 'Jtot', 'dMdt', 'frot', 'dens_c', 'temp_c', 'Rsurf', 'Lsurf', 'Teff', 'vrot', '[N/H]', 'Gedd', 'gam_ave', 'mach_max', 'Brad', 'fconf', 'fbrak', 'eta_B', 'omgs[d-1]', 'omgc[d-1]', 'Lnuc', 'Lnu', 'Lrad']}, {'index': 6, 'header': '# 1:stg 2:jcma 3:nmlo  4:ndv         5:time        6:dtime         7:Mtot         8:Etot         9:Jtot     10:dMdt     11:frot   12:dens_c   13:temp_c    14:Rsurf    15:Lsurf     16:Teff     17:vrot    18:[N/H]     19:Gedd  20:gam_ave 21:mach_max     22:Brad    23:fconf    24:fbrak    25:eta_B26:omgs[d-1]27:omgc[d-1]     28:Lnuc      29:Lnu     30:Lrad', 'start_line': 191, 'end_line': 257, 'var_names': ['stg', 'jcma', 'nmlo', 'ndv', 'time', 'dtime', 'Mtot', 'Etot', 'Jtot', 'dMdt', 'frot', 'dens_c', 'temp_c', 'Rsurf', 'Lsurf', 'Teff', 'vrot', '[N/H]', 'Gedd', 'gam_ave', 'mach_max', 'Brad', 'fconf', 'fbrak', 'eta_B', 'omgs[d-1]', 'omgc[d-1]', 'Lnuc', 'Lnu', 'Lrad']}, {'index': 7, 'header': '# 1:stg 2:jcma 3:nmlo  4:ndv         5:time        6:dtime         7:Mtot         8:Etot         9:Jtot     10:dMdt     11:frot   12:dens_c   13:temp_c    14:Rsurf    15:Lsurf     16:Teff     17:vrot    18:[N/H]     19:Gedd  20:gam_ave 21:mach_max     22:Brad    23:fconf    24:fbrak    25:eta_B26:omgs[d-1]27:omgc[d-1]     28:Lnuc      29:Lnu     30:Lrad', 'start_line': 258, 'end_line': 2726, 'var_names': ['stg', 'jcma', 'nmlo', 'ndv', 'time', 'dtime', 'Mtot', 'Etot', 'Jtot', 'dMdt', 'frot', 'dens_c', 'temp_c', 'Rsurf', 'Lsurf', 'Teff', 'vrot', '[N/H]', 'Gedd', 'gam_ave', 'mach_max', 'Brad', 'fconf', 'fbrak', 'eta_B', 'omgs[d-1]', 'omgc[d-1]', 'Lnuc', 'Lnu', 'Lrad']}, {'index': 8, 'header': '# 1:stg 2:jcma 3:nmlo  4:ndv         5:time        6:dtime         7:Mtot         8:Etot         9:Jtot     10:dMdt     11:frot   12:dens_c   13:temp_c    14:Rsurf    15:Lsurf     16:Teff     17:vrot    18:[N/H]     19:Gedd  20:gam_ave 21:mach_max     22:Brad    23:fconf    24:fbrak    25:eta_B26:omgs[d-1]27:omgc[d-1]     28:Lnuc      29:Lnu     30:Lrad', 'start_line': 2727, 'end_line': 2728, 'var_names': ['stg', 'jcma', 'nmlo', 'ndv', 'time', 'dtime', 'Mtot', 'Etot', 'Jtot', 'dMdt', 'frot', 'dens_c', 'temp_c', 'Rsurf', 'Lsurf', 'Teff', 'vrot', '[N/H]', 'Gedd', 'gam_ave', 'mach_max', 'Brad', 'fconf', 'fbrak', 'eta_B', 'omgs[d-1]', 'omgc[d-1]', 'Lnuc', 'Lnu', 'Lrad']}, {'index': 9, 'header': '# 1:stg 2:jcma 3:nmlo  4:ndv         5:time        6:dtime         7:Mtot         8:Etot         9:Jtot     10:dMdt     11:frot   12:dens_c   13:temp_c    14:Rsurf    15:Lsurf     16:Teff     17:vrot    18:[N/H]     19:Gedd  20:gam_ave 21:mach_max     22:Brad    23:fconf    24:fbrak    25:eta_B26:omgs[d-1]27:omgc[d-1]     28:Lnuc      29:Lnu     30:Lrad', 'start_line': 2729, 'end_line': 2863, 'var_names': ['stg', 'jcma', 'nmlo', 'ndv', 'time', 'dtime', 'Mtot', 'Etot', 'Jtot', 'dMdt', 'frot', 'dens_c', 'temp_c', 'Rsurf', 'Lsurf', 'Teff', 'vrot', '[N/H]', 'Gedd', 'gam_ave', 'mach_max', 'Brad', 'fconf', 'fbrak', 'eta_B', 'omgs[d-1]', 'omgc[d-1]', 'Lnuc', 'Lnu', 'Lrad']}]\n"
     ]
    }
   ],
   "source": [
    "# read summary/summary.txt\n",
    "history = hr.HoshiHistory(hm.summary_dir)\n",
    "print(history.path)\n",
    "print(history.count_runs())\n",
    "print(history.list_runs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df15c0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanby/repos/HOSHI_WorkFlow/src/hoshi_workflow/hoshi_reader/hoshi_reader.py:192: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\n",
      "/home/tanby/repos/HOSHI_WorkFlow/src/hoshi_workflow/hoshi_reader/hoshi_reader.py:192: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\n",
      "WARNING:root:End index 2400 not found in run 8, skipping it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanby/repos/HOSHI_WorkFlow/src/hoshi_workflow/hoshi_reader/hoshi_reader.py:192: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "df = history._generate_combined_data(save_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50794673",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid path provided. Path should be either a directory or a summary.txt file.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m hist = \u001b[43mhr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHoshiHistory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m+\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/summary/summary_combined.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/HOSHI_WorkFlow/src/hoshi_workflow/hoshi_reader/hoshi_reader.py:107\u001b[39m, in \u001b[36mHoshiHistory.__init__\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m    105\u001b[39m     \u001b[38;5;28mself\u001b[39m.path = p\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    108\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mInvalid path provided. Path should be either a directory or a summary.txt file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    109\u001b[39m     )\n\u001b[32m    111\u001b[39m \u001b[38;5;28mself\u001b[39m.var_names = \u001b[38;5;28mself\u001b[39m._get_var_names()\n",
      "\u001b[31mValueError\u001b[39m: Invalid path provided. Path should be either a directory or a summary.txt file."
     ]
    }
   ],
   "source": [
    "hist = hr.HoshiHistory(path+\"/summary/summary_combined.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445cb36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2401 2402 2403 2404 2405 2406 2407 2408 2409 2410 2411 2412 2413 2414\n",
      " 2415 2416 2417 2418 2419 2420 2421 2422 2423 2424 2425 2426 2427 2428\n",
      " 2429 2430 2431 2432 2433 2434 2435 2436 2437 2438 2439 2440 2441 2442\n",
      " 2443 2444 2445 2446 2447 2448 2449 2450 2451 2452 2453 2454 2455 2456\n",
      " 2457 2458 2459 2460 2461 2462 2463 2464 2465 2466 2467 2468 2469 2470\n",
      " 2471 2472 2473 2474 2475 2476 2477 2478 2479 2480 2481 2482 2483 2484\n",
      " 2485 2486 2487 2488 2489 2490 2491 2492 2493 2494 2495 2496 2497 2498\n",
      " 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 2509 2510 2511 2512\n",
      " 2513 2514 2515 2516 2517 2518 2519 2520 2521 2522 2523 2524 2525 2526\n",
      " 2527 2528 2529 2530 2531 2532 2533 2534]\n",
      "[2401]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanby/repos/HOSHI_WorkFlow/src/hoshi_workflow/hoshi_reader/hoshi_reader.py:192: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\n",
      "/home/tanby/repos/HOSHI_WorkFlow/src/hoshi_workflow/hoshi_reader/hoshi_reader.py:192: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\n",
      "/home/tanby/repos/HOSHI_WorkFlow/src/hoshi_workflow/hoshi_reader/hoshi_reader.py:192: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\n",
      "/home/tanby/repos/HOSHI_WorkFlow/src/hoshi_workflow/hoshi_reader/hoshi_reader.py:192: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\n",
      "/home/tanby/repos/HOSHI_WorkFlow/src/hoshi_workflow/hoshi_reader/hoshi_reader.py:192: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\n",
      "/home/tanby/repos/HOSHI_WorkFlow/src/hoshi_workflow/hoshi_reader/hoshi_reader.py:192: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\n",
      "/home/tanby/repos/HOSHI_WorkFlow/src/hoshi_workflow/hoshi_reader/hoshi_reader.py:192: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\n",
      "/home/tanby/repos/HOSHI_WorkFlow/src/hoshi_workflow/hoshi_reader/hoshi_reader.py:192: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\n",
      "/home/tanby/repos/HOSHI_WorkFlow/src/hoshi_workflow/hoshi_reader/hoshi_reader.py:192: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1    2    3 ... 2466 2467 2468]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65  0]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34  0]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35  0]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36  0]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  0]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37  0]\n"
     ]
    }
   ],
   "source": [
    "for idx_run in range(history.count_runs(), 0, -1):\n",
    "    df = history.read_run(idx_run)\n",
    "    stg = df['stg'].to_numpy(dtype=int)   # or df['stg'].values\n",
    "    print(stg)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f85c0a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End index of the last run: 2400"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error: end index 2400 not found in run 8, skipping it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanby/repos/HOSHI_WorkFlow/src/hoshi_workflow/hoshi_reader/hoshi_reader.py:192: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\n",
      "/home/tanby/repos/HOSHI_WorkFlow/src/hoshi_workflow/hoshi_reader/hoshi_reader.py:192: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\n",
      "/home/tanby/repos/HOSHI_WorkFlow/src/hoshi_workflow/hoshi_reader/hoshi_reader.py:192: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found end index 2400 in run 7.\n",
      "Combined DataFrame now has 2535 rows.\n",
      "Reached the beginning of the data.\n",
      "No missing stages, data is continuous from 1 to 2534.\n"
     ]
    }
   ],
   "source": [
    "idx_run = history.count_runs()\n",
    "df_combined = history.read_run(idx_run)\n",
    "stg = df_combined['stg'].to_numpy(dtype=int)\n",
    "end_idx = stg[0] - 1\n",
    "print(f\"End index of the last run: {end_idx}\")\n",
    "\n",
    "while idx_run > 0:\n",
    "    idx_run -= 1\n",
    "    df = history.read_run(idx_run)\n",
    "    stg = df['stg'].to_numpy(dtype=int)\n",
    "    if not end_idx in stg:\n",
    "        print(f\"Error: end index {end_idx} not found in run {idx_run}, skipping it.\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"Found end index {end_idx} in run {idx_run}.\")\n",
    "        cut_idx = np.where(stg == end_idx)[0][0]\n",
    "        df_cut = df.iloc[:cut_idx+2]\n",
    "        df_combined = pd.concat([df_cut, df_combined], ignore_index=True)\n",
    "        print(f\"Combined DataFrame now has {len(df_combined)} rows.\")\n",
    "\n",
    "        stg_list = df_combined['stg'].to_numpy(dtype=int)\n",
    "        if stg_list[0] == 1:\n",
    "            print(\"Reached the beginning of the data.\")\n",
    "            break\n",
    "        else:\n",
    "            end_idx = stg_list[0] - 1\n",
    "        \n",
    "check_list = np.arange(stg_list[0], stg_list[-1]+1, dtype=int)\n",
    "missing_stages = set(check_list) - set(stg_list)\n",
    "if missing_stages:\n",
    "    print(f\"Missing stages: {sorted(missing_stages)}\")\n",
    "else:\n",
    "    print(f\"No missing stages, data is continuous from {stg_list[0]} to {stg_list[-1]}.\")\n",
    "#plt.plot(stg_list)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
